##                                         一种通过数据库方式提升查询效率的方法

- [ ] ​                                                    (by dada 2023.09.20 PM)

#### 一、环境准备

1. PC安装并运行node  环境
2. 申请开通mixin bot 机器人 
3. npm 导入“mixin -node- sdk”模块
4. npm 导入”Sqlite3 “ 和”sequelize“ 数据库相关的模块
5. 掌握 nodejs 、数据库和 Mixin SDK API 开发基础知识及能力。

####  二、需求背景

​      漫长的2分钟，近120秒的等待。随着9月初完成了第一期对赌共学活动，紧接着开始了第二期的活动；但在第一期中，有一个问题一直困扰着：当向转账助手发出查询所有参与人员转账清单指令时（第一期人数是21人；转入和转出各21条、测试8条，共50条记录）；需要等待的时间为：初步测试查询一条的时间为2秒，50条x 2秒 = 100秒，约2分钟的时间，这是网络和系统保持稳定的情况下的结果；遇到环境有波动不稳定，消息就石沉大海了；当时，主要考虑的是能把流程跑通，消息能发出来就行；而且该需求为偶发，服务对象主要是运营组的几位伙伴，周期内查询的数据无变化，该功能问题一直将就到一期结束。到了二期，人数和数据增加、需要及时掌握报名转账信息，必须要提升查询效率，更好服务好伙伴们，不能再往后拖啦...

<img src="https://raw.githubusercontent.com/Dada01Github/images/master/image-20230921093710293.png" alt="image-20230921093710293" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/Dada01Github/images/master/image-20230921093950824.png" alt="image-20230921093950824" style="zoom:85%;" />



#### 三、原因定位

​         要解决问题，首先要定位原因。通过对该查询需求进行详细分析，包括要发送的流程及数据。重点在数据的采集、加工和转发上，尤其是采集上。为什么会慢？时间开销在哪里？对原代码进行了逐行逐句的分析，发现了执行代码程序中，返回给用户的消息相关的数据，需要将所有的清单用户，大部分关键字段，如用户全名、id、symbol等需要逐个逐个去mixin网络中去查询，结果返回来后，存储在内存中，待21个用户全部轮询完，打包转发消息；转入和转出两组消息使用的是同样的过程。

​       总结一下慢的主要原因：数据采集的过程是根据用户id逐个查询，再将查询结果整合加工，打包转发出去，这是个串行完成的过程；最主要的时间花销在后台转账助手与mixin主网络的一来一回的交互上，包括：identity_number、full name、symbol等，即使提高了单条的查询速度，但叠加50次，累计下来就严重拖慢了；因此该问题重点要解决的是：转发信息关键字段的数据采集环节。

<img src="https://raw.githubusercontent.com/Dada01Github/images/master/cd43c6f4-56b4-48f8-913e-87faabab4980.png" alt="cd43c6f4-56b4-48f8-913e-87faabab4980" style="zoom:67%;" />

#### 四、方案选择

​         定位了问题的主要原因，离解决就不远了。上述原因导致的执行的结果是：每一次查询，都是从新开始，哪怕紧接着重复查询，也是从新开始，完全是在浪费网络资源，而且是高度依赖网络效率。怎么办？如果将每次查询的结果保留下来，存在一个文件里，不就能解决重复向主网发起查询的过程了？而且读取硬盘文件的时间远远比在通过网络查询的速度要快，效率更高；如果有新增的用户记录，及时更新补充到文件，不就可以解决了！再往前点想，如果在首次发其转账时，把相关的信息保留下来，不是效率更高？！还有什么一劳永逸的方法吗？保留在数据库中，不是更方便、更快捷、更高效，毕竟数据库有一套标准高效的CRUD指令集（C、U、R、D 分别代表 **Create（增）、Delete(删)、 Update（改）、Read（查）**是数据库四种基本操作。），想想都有点小激动啦！

####   五、代码验证

​       有了解决思路方案，接下来就是更新代码和测试验证。在程序代码方面，一是更新数据库表的关键字段定义；二是消息的创建和保存：从收到的转账消息，提取出需要的字段（user_id/amount/asset/等），以及从mixin主网查询到的消息字段（id、full name、symbol·等），通过数据库create 指令将其全部创建和保存在相应的数据库表中；三是消息关键字段的查询和提取：从过去向mixin主网查询的，指向数据库表查询，通过数据库查询指令 findall 即可查询到所有保存在数据库中用户转账清单消息。

<img src="https://raw.githubusercontent.com/Dada01Github/images/master/image-20230920231507785.png" alt="image-20230920231507785" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/Dada01Github/images/master/image-20230920225557504.png" alt="image-20230920225557504" style="zoom: 67%;" />

​      <img src="https://raw.githubusercontent.com/Dada01Github/images/master/image-20230920231747957.png" alt="image-20230920231747957" style="zoom: 50%;" />

​         验证结果，飞一般的感觉，爽！查询二期（转入+转出）62条记录，从指令下发，到返回消息，秒到！效率提升了百倍，大大超出预期。

<img src="https://raw.githubusercontent.com/Dada01Github/images/master/image-20230921092510908.png" alt="image-20230921092510908" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/Dada01Github/images/master/image-20230921093140059.png" alt="image-20230921093140059" style="zoom: 75%;" />

####  六、复盘小结

​         2分钟长等待时延的问题，困扰了90天；分析定位、写代码、运行测试用时90分钟，结果滴答2秒收到返回消息。如何做到的？小结一下：首先也是最关键的一步，分析定位问题的主要原因，再选择更高效成熟的解决方案；实施原则：1.串行改并行：转账助手机器人一次从数据库表中查询到所有记录，代替了原来逐个查询保存串行操作，用批量查询代替逐条遍历；2.实时入库及时更新：由原来按指令启动，即用即查、用完即弃；转变为，实时保存新增，及时更新变化；即，需要的数据平时存、及时存，提前存。3.分散变集中：将分散在网络中的关键段数据统一集中到数据库文件中，即查即用，用查阅库存代替实时网络访问，稳定高效。通过本实战方法，解决了本案例查询长时延的问题，同时为后续类似的问题（或需求）积累了一种思路和方法。

​        写到这里，你可能会提出疑问：此方法这么高效，也很成熟的做法，为什么在项目初期就没有选择该方案呢？是否还有更佳的选择？...... 欢迎各位战友一起讨论，共同探索更有效更高效的思路和方法，一起学习成长。

